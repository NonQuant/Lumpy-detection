{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim.lr_scheduler as lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LumpyDataset(Dataset):\n",
    "    def __init__(self, images, labels) -> None:\n",
    "        self.X = images\n",
    "        self.y = labels\n",
    "        # function for images transformations\n",
    "        # TODO: try AutoAugment(AutoAugmentPolicy.IMAGENET)\n",
    "        self.random_transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.RandomRotation(30),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ColorJitter(\n",
    "                brightness=0.1, contrast=0.1),\n",
    "            transforms.RandomAffine(\n",
    "                degrees=(0, 30),\n",
    "                translate=(0, 0.2),\n",
    "                scale=(0.9, 1)\n",
    "            ),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def get_labels(self):\n",
    "        return self.y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        num_augment = 8\n",
    "        augmented_batch = []\n",
    "        # creating augmented data\n",
    "        for i in range(num_augment):\n",
    "            new_item = self.random_transform(self.X[index])\n",
    "            augmented_batch.append(new_item)\n",
    "        # labels with one-hot encoding\n",
    "        label = torch.Tensor([self.y[index]])\n",
    "\n",
    "        new_labels = [label, label, label, label, label, label, label, label]\n",
    "\n",
    "        return torch.stack(augmented_batch), torch.stack(new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading all dataloaders\n",
    "with open(\"./variables/train_loader.pickle\", \"rb\") as f:\n",
    "    train_loader = pickle.load(f)\n",
    "with open(\"./variables/valid_loader.pickle\", \"rb\") as f:\n",
    "    valid_loader = pickle.load(f)\n",
    "with open(\"./variables/test_loader.pickle\", \"rb\") as f:\n",
    "    test_loader = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading pretrained ResNet50 model\n",
    "weights = torchvision.models.ResNet50_Weights.DEFAULT\n",
    "resnet = torchvision.models.resnet50(weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfreezing model's parameters\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "n_inputs = resnet.fc.in_features\n",
    "# modifying last layer of model\n",
    "resnet.fc = nn.Sequential(nn.Linear(n_inputs, 1024),\n",
    "                          nn.SELU(),\n",
    "                          nn.Dropout(p=.4),\n",
    "                          nn.Linear(1024, 1024),\n",
    "                          nn.SELU(),\n",
    "                          nn.Dropout(p=0.4),\n",
    "                          nn.Linear(1024, 1))\n",
    "\n",
    "for name, child in resnet.named_children():\n",
    "    for name2, params in child.named_parameters():\n",
    "        params.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use GPU if available\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (1): SELU()\n",
       "    (2): Dropout(p=0.4, inplace=False)\n",
       "    (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (4): SELU()\n",
       "    (5): Dropout(p=0.4, inplace=False)\n",
       "    (6): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "resnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining loss function and optimizer\n",
    "lossfunc = nn.BCEWithLogitsLoss().to(device)\n",
    "optimizer = torch.optim.Adam(resnet.parameters(), lr=3e-4)\n",
    "\n",
    "train_losses, test_losses, train_correct, test_correct = [], [], [], []\n",
    "\n",
    "scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.6, total_iters=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, epoch, acc, foldername=\"./best_models/\"):\n",
    "    torch.save(state, foldername + f\"epoch_{epoch}_acc_{acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, max_counter, threshold) -> None:\n",
    "        self.stop_counter = 0\n",
    "        self.last_best = 0\n",
    "        self.max_counter = max_counter\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def stop_learning(self, accuracy):\n",
    "        if accuracy <= self.last_best or abs(accuracy - self.last_best) <= self.threshold:\n",
    "            self.stop_counter += 1\n",
    "            print(\"MODEL DID NOT IMPROVE FROM\", self.last_best)\n",
    "        else:\n",
    "            self.stop_counter = 0\n",
    "\n",
    "        if self.stop_counter == self.max_counter:\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "sample_size = 8\n",
    "def train_the_model(model, epochs):\n",
    "    start_time = time.time()\n",
    "    for epoch_i in range(epochs):\n",
    "        train_corr, test_corr = 0, 0\n",
    "        total_num = 0\n",
    "\n",
    "        epoch_start = time.time()\n",
    "        batch_corr = 0\n",
    "        for batch_num, (X, y) in enumerate(train_loader):\n",
    "            total_num += sample_size * batch_size\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            y_pred = resnet(X.view(-1, 3, 225, 225))\n",
    "            loss = lossfunc(y_pred, y.view(batch_size * sample_size, -1)) # 16 samples in batch, 3 images in one sample\n",
    "            # find predicted labels\n",
    "            predicted = y_pred.view(batch_size * sample_size) > .5\n",
    "\n",
    "            # calculate the amount of correct predictions in batch\n",
    "            batch_corr += (predicted.long() == y.view(batch_size*sample_size)).sum()\n",
    "            # backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_corr = batch_corr.item() / (total_num)\n",
    "        epoch_end = time.time() - epoch_start\n",
    "        print(f\"Epoch {epoch_i + 1} | Batch {(batch_num + 1) * batch_size}\\nAccuracy: {train_corr:2.2f} | Loss: {loss.item():2.4f} | Duration: {epoch_end / 60:.2f} minutes\")\n",
    "\n",
    "        train_b = batch_num\n",
    "        train_losses.append(loss)\n",
    "        train_correct.append(train_corr)\n",
    "\n",
    "        X, y = None, None\n",
    "\n",
    "        with torch.no_grad():\n",
    "            total_num = 0\n",
    "            for batch_num, (X, y) in enumerate(valid_loader):\n",
    "                total_num += sample_size * batch_size\n",
    "                X, y = X.to(device), y.to(device)\n",
    "\n",
    "                y_val = resnet(X.view(-1, 3, 225, 225))\n",
    "                predicted = y_val.view(batch_size * sample_size) > .5\n",
    "\n",
    "                test_corr += (predicted.long() == y.view(batch_size * sample_size)).sum()\n",
    "        \n",
    "        loss = lossfunc(y_val, y.view(batch_size * sample_size, 1))\n",
    "\n",
    "        val_acc = test_corr.item() / (total_num)\n",
    "\n",
    "        print(f\"Validation Accuracy: {val_acc * 100:2.2f} | Validation loss: {loss.item():2.4f}\\n\")\n",
    "\n",
    "        save_checkpoint(resnet.state_dict(),\n",
    "                        epoch_i + 1,\n",
    "                        val_acc)\n",
    "\n",
    "        test_b = batch_num\n",
    "        test_losses.append(loss)\n",
    "        test_correct.append(val_acc)\n",
    "\n",
    "        before_lr = optimizer.param_groups[0][\"lr\"]\n",
    "        scheduler.step()\n",
    "        after_lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "        print(f\"LR {before_lr * 10000: .3f}-e4 -> {after_lr * 10000: .3f}-e4\")\n",
    "\n",
    "        if earlystopping.stop_learning(val_acc):\n",
    "            break\n",
    "\n",
    "    end_time = time.time() - start_time\n",
    "\n",
    "    print(f\"\\nTraining Duration: {end_time / 60:.2f} minutes\")\n",
    "    print(f\"GPU memory used: {torch.cuda.memory_allocated()} kb\")\n",
    "    print(f\"GPU memory cached: {torch.cuda.memory_cached()} kb\")\n",
    "\n",
    "    return model, train_losses, test_losses, train_correct, test_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Batch 520\n",
      "Accuracy: 0.85 | Loss: 0.3415 | Duration: 10.60 minutes\n",
      "Validation Accuracy: 77.15 | Validation loss: 0.4835\n",
      "\n",
      "LR  3.000-e4 ->  2.920-e4\n",
      "Epoch 2 | Batch 520\n",
      "Accuracy: 0.89 | Loss: 0.2303 | Duration: 12.15 minutes\n",
      "Validation Accuracy: 91.80 | Validation loss: 0.0686\n",
      "\n",
      "LR  2.920-e4 ->  2.840-e4\n",
      "Epoch 3 | Batch 520\n",
      "Accuracy: 0.91 | Loss: 0.4360 | Duration: 12.06 minutes\n",
      "Validation Accuracy: 91.99 | Validation loss: 0.1975\n",
      "\n",
      "LR  2.840-e4 ->  2.760-e4\n",
      "Epoch 4 | Batch 520\n",
      "Accuracy: 0.96 | Loss: 0.1942 | Duration: 12.03 minutes\n",
      "Validation Accuracy: 86.72 | Validation loss: 0.6745\n",
      "\n",
      "LR  2.760-e4 ->  2.680-e4\n",
      "Epoch 5 | Batch 520\n",
      "Accuracy: 0.94 | Loss: 0.0315 | Duration: 10.92 minutes\n",
      "Validation Accuracy: 88.67 | Validation loss: 0.3657\n",
      "\n",
      "LR  2.680-e4 ->  2.600-e4\n",
      "\n",
      "Training Duration: 59.16 minutes\n",
      "GPU memory used: 1225899008 kb\n",
      "GPU memory cached: 7650410496 kb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\husai\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\cuda\\memory.py:416: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "earlystopping = EarlyStopping(3, 0.2)\n",
    "\n",
    "best_prec1 = 2\n",
    "\n",
    "batch_num, train_b, test_b = None, None, None\n",
    "\n",
    "model, train_losses, test_losses, train_correct, test_correct = train_the_model(resnet, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_dict = torch.load(\"./best_models/epoch_5_acc_0.88671875\")\n",
    "best_model = torchvision.models.resnet50(weights=weights)\n",
    "best_model.fc = nn.Sequential(nn.Linear(n_inputs, 1024),\n",
    "                          nn.SELU(),\n",
    "                          nn.Dropout(p=.4),\n",
    "                          nn.Linear(1024, 1024),\n",
    "                          nn.SELU(),\n",
    "                          nn.Dropout(p=0.4),\n",
    "                          nn.Linear(1024, 1))\n",
    "best_model.to(device)\n",
    "best_model.load_state_dict(best_model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(53, device='cuda:0')\n",
      "tensor(113, device='cuda:0')\n",
      "tensor(146, device='cuda:0')\n",
      "tensor(210, device='cuda:0')\n",
      "tensor(259, device='cuda:0')\n",
      "tensor(315, device='cuda:0')\n",
      "tensor(372, device='cuda:0')\n",
      "tensor(436, device='cuda:0')\n",
      "Test Loss: 0.0125\n",
      "Test accuracy: 85.15625\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "sample_size = 8\n",
    "# test model with no gradient updates\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    test_loss = []\n",
    "    test_corr = 0\n",
    "    labels = []\n",
    "    pred = []\n",
    "    counter = 0\n",
    "    # perform test set evaluation batch wise\n",
    "    for (X, y) in test_loader:\n",
    "        # set label to use CUDA if available\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # append original labels\n",
    "        labels.append(y.view(-1, 1))\n",
    "\n",
    "        y_pred = best_model(X.view(-1, 3, 225, 225))\n",
    "        loss = lossfunc(y_pred, y.view(batch_size*sample_size, -1)) # 16 samples in batch, 3 images in one sample\n",
    "\n",
    "        # get argmax of predicted values, which is our label\n",
    "        predicted = (y_pred.view(batch_size*sample_size) > .5).long()\n",
    "        # append predicted label\n",
    "        pred.append(y_pred)\n",
    "\n",
    "        # increment correct with correcly predicted labels per batch\n",
    "        test_corr += (predicted == y.view(batch_size*sample_size)).sum()\n",
    "        print(test_corr)\n",
    "\n",
    "        test_loss.append(loss)\n",
    "        counter += 1\n",
    "print(f\"Test Loss: {test_loss[-1].item():.4f}\")\n",
    "print(f\"Test accuracy: {test_corr * 100 / (sample_size*batch_size*counter)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
