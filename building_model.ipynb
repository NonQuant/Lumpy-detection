{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LumpyDataset(Dataset):\n",
    "    def __init__(self, images, labels) -> None:\n",
    "        self.X = images\n",
    "        self.y = labels\n",
    "        # function for images transformations\n",
    "        # TODO: try AutoAugment(AutoAugmentPolicy.IMAGENET)\n",
    "        self.random_transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            # transforms.RandomHorizontalFlip(),\n",
    "            # transforms.ColorJitter(\n",
    "            #     brightness=0.3, contrast=0.3),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        num_augment = 3\n",
    "        augmented_batch = []\n",
    "        # creating augmented data\n",
    "        for i in range(num_augment):\n",
    "            new_item = self.random_transform(self.X[index])\n",
    "            augmented_batch.append(new_item)\n",
    "        # labels with one-hot encoding\n",
    "        label = torch.Tensor([self.y[index]])\n",
    "\n",
    "        new_labels = [label, label, label]\n",
    "\n",
    "        return torch.stack(augmented_batch), torch.stack(new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading all dataloaders\n",
    "with open(\"./variables/train_loader.pickle\", \"rb\") as f:\n",
    "    train_loader = pickle.load(f)\n",
    "with open(\"./variables/valid_loader.pickle\", \"rb\") as f:\n",
    "    valid_loader = pickle.load(f)\n",
    "with open(\"./variables/test_loader.pickle\", \"rb\") as f:\n",
    "    test_loader = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading pretrained ResNet50 model\n",
    "weights = torchvision.models.ResNet50_Weights.DEFAULT\n",
    "resnet = torchvision.models.resnet50(weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfreezing model's parameters\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "n_inputs = resnet.fc.in_features\n",
    "# modifying last layer of model\n",
    "resnet.fc = nn.Sequential(nn.Linear(n_inputs, 2048),\n",
    "                          nn.SELU(),\n",
    "                          nn.Dropout(p=.4),\n",
    "                          nn.Linear(2048, 2048),\n",
    "                          nn.SELU(),\n",
    "                          nn.Dropout(p=0.4),\n",
    "                          nn.Linear(2048, 1))\n",
    "\n",
    "for name, child in resnet.named_children():\n",
    "    for name2, params in child.named_parameters():\n",
    "        params.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use GPU if available\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (1): SELU()\n",
       "    (2): Dropout(p=0.4, inplace=False)\n",
       "    (3): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (4): SELU()\n",
       "    (5): Dropout(p=0.4, inplace=False)\n",
       "    (6): Linear(in_features=2048, out_features=256, bias=True)\n",
       "    (7): SELU()\n",
       "    (8): Dropout(p=0.4, inplace=False)\n",
       "    (9): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "resnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining loss function and optimizer\n",
    "lossfunc = nn.BCEWithLogitsLoss().to(device)\n",
    "optimizer = torch.optim.Adam(resnet.parameters(), lr=3e-4)\n",
    "\n",
    "train_losses, test_losses, train_correct, test_correct = [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename=\"./best_models/resnet_checkpoint.pth.tar\"):\n",
    "    if is_best:\n",
    "        torch.save(state, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, max_counter, threshold) -> None:\n",
    "        self.stop_counter = 0\n",
    "        self.last_best = 0\n",
    "        self.max_counter = max_counter\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def stop_learning(self, accuracy):\n",
    "        if accuracy <= self.last_best or abs(accuracy - self.last_best) <= self.threshold:\n",
    "            self.stop_counter += 1\n",
    "            print(\"MODEL DID NOT IMPROVE FROM\", self.last_best)\n",
    "        else:\n",
    "            self.stop_counter = 0\n",
    "\n",
    "        if self.stop_counter == self.max_counter:\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2162, device='cuda:0')\n",
      "Epoch 1 | Batch 1488\n",
      "Accuracy: 0.97 | Loss: 0.0089 | Duration: 5.23 minutes\n",
      "tensor(20, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "Validation Accuracy: 83.33 | Validation loss: 0.7814\n",
      "\n",
      "tensor(2171, device='cuda:0')\n",
      "Epoch 2 | Batch 1488\n",
      "Accuracy: 0.97 | Loss: 0.0004 | Duration: 4.94 minutes\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(11, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(23, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "Validation Accuracy: 82.58 | Validation loss: 0.2917\n",
      "\n",
      "tensor(2210, device='cuda:0')\n",
      "Epoch 3 | Batch 1488\n",
      "Accuracy: 0.99 | Loss: 0.0003 | Duration: 4.95 minutes\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "Validation Accuracy: 81.82 | Validation loss: 1.7888\n",
      "\n",
      "tensor(2208, device='cuda:0')\n",
      "Epoch 4 | Batch 1488\n",
      "Accuracy: 0.99 | Loss: 0.0001 | Duration: 4.93 minutes\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(14, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(12, device='cuda:0')\n",
      "Validation Accuracy: 77.27 | Validation loss: 2.8242\n",
      "\n",
      "tensor(2232, device='cuda:0')\n",
      "Epoch 5 | Batch 1488\n",
      "Accuracy: 1.00 | Loss: 0.0001 | Duration: 4.94 minutes\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(23, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "Validation Accuracy: 79.17 | Validation loss: 1.4680\n",
      "\n",
      "tensor(2155, device='cuda:0')\n",
      "Epoch 6 | Batch 1488\n",
      "Accuracy: 0.97 | Loss: 0.0188 | Duration: 4.93 minutes\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "Validation Accuracy: 81.44 | Validation loss: 0.2514\n",
      "\n",
      "tensor(2112, device='cuda:0')\n",
      "Epoch 7 | Batch 1488\n",
      "Accuracy: 0.95 | Loss: 0.2155 | Duration: 4.93 minutes\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "Validation Accuracy: 81.82 | Validation loss: 0.0167\n",
      "\n",
      "tensor(2168, device='cuda:0')\n",
      "Epoch 8 | Batch 1488\n",
      "Accuracy: 0.97 | Loss: 0.0015 | Duration: 4.68 minutes\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(12, device='cuda:0')\n",
      "Validation Accuracy: 81.06 | Validation loss: 1.4826\n",
      "\n",
      "tensor(2203, device='cuda:0')\n",
      "Epoch 9 | Batch 1488\n",
      "Accuracy: 0.99 | Loss: 0.0051 | Duration: 4.90 minutes\n",
      "tensor(22, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(12, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "Validation Accuracy: 84.47 | Validation loss: 0.4144\n",
      "\n",
      "tensor(2208, device='cuda:0')\n",
      "Epoch 10 | Batch 1488\n",
      "Accuracy: 0.99 | Loss: 0.0124 | Duration: 4.86 minutes\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(12, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "Validation Accuracy: 80.68 | Validation loss: 0.0004\n",
      "\n",
      "tensor(2216, device='cuda:0')\n",
      "Epoch 11 | Batch 1488\n",
      "Accuracy: 0.99 | Loss: 0.0045 | Duration: 4.81 minutes\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "Validation Accuracy: 80.68 | Validation loss: 0.3211\n",
      "\n",
      "tensor(2229, device='cuda:0')\n",
      "Epoch 12 | Batch 1488\n",
      "Accuracy: 1.00 | Loss: 0.0003 | Duration: 4.78 minutes\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "Validation Accuracy: 84.09 | Validation loss: 0.0014\n",
      "\n",
      "tensor(2229, device='cuda:0')\n",
      "Epoch 13 | Batch 1488\n",
      "Accuracy: 1.00 | Loss: 0.0010 | Duration: 4.76 minutes\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(12, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "Validation Accuracy: 82.95 | Validation loss: 1.9059\n",
      "\n",
      "tensor(2232, device='cuda:0')\n",
      "Epoch 14 | Batch 1488\n",
      "Accuracy: 1.00 | Loss: 0.0000 | Duration: 4.78 minutes\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "Validation Accuracy: 81.82 | Validation loss: 4.1925\n",
      "\n",
      "tensor(2232, device='cuda:0')\n",
      "Epoch 15 | Batch 1488\n",
      "Accuracy: 1.00 | Loss: 0.0000 | Duration: 4.75 minutes\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(12, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "Validation Accuracy: 80.68 | Validation loss: 0.2051\n",
      "\n",
      "tensor(2232, device='cuda:0')\n",
      "Epoch 16 | Batch 1488\n",
      "Accuracy: 1.00 | Loss: 0.0000 | Duration: 4.75 minutes\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(23, device='cuda:0')\n",
      "tensor(23, device='cuda:0')\n",
      "tensor(12, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "Validation Accuracy: 86.74 | Validation loss: 1.5209\n",
      "\n",
      "tensor(2232, device='cuda:0')\n",
      "Epoch 17 | Batch 1488\n",
      "Accuracy: 1.00 | Loss: 0.0000 | Duration: 4.75 minutes\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "Validation Accuracy: 85.23 | Validation loss: 1.3115\n",
      "\n",
      "tensor(2232, device='cuda:0')\n",
      "Epoch 18 | Batch 1488\n",
      "Accuracy: 1.00 | Loss: 0.0000 | Duration: 4.78 minutes\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(20, device='cuda:0')\n",
      "Validation Accuracy: 83.71 | Validation loss: 0.3062\n",
      "\n",
      "tensor(2232, device='cuda:0')\n",
      "Epoch 19 | Batch 1488\n",
      "Accuracy: 1.00 | Loss: 0.0000 | Duration: 4.75 minutes\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "Validation Accuracy: 88.64 | Validation loss: 1.2732\n",
      "\n",
      "tensor(2232, device='cuda:0')\n",
      "Epoch 20 | Batch 1488\n",
      "Accuracy: 1.00 | Loss: 0.0000 | Duration: 4.75 minutes\n",
      "tensor(23, device='cuda:0')\n",
      "tensor(23, device='cuda:0')\n",
      "tensor(24, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(22, device='cuda:0')\n",
      "tensor(21, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "Validation Accuracy: 87.12 | Validation loss: 1.7959\n",
      "\n",
      "\n",
      "Training Duration: 98.86 minutes\n",
      "GPU memory used: 561323520 kb\n",
      "GPU memory cached: 5341446144 kb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\husai\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\cuda\\memory.py:416: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "earlystopping = EarlyStopping(3, 0.2)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "best_prec1 = 2\n",
    "\n",
    "batch_num, train_b, test_b = None, None, None\n",
    "\n",
    "for epoch_i in range(epochs):\n",
    "    train_corr, test_corr = 0, 0\n",
    "    total_num = 0\n",
    "\n",
    "    epoch_start = time.time()\n",
    "    batch_corr = 0\n",
    "    for batch_num, (X, y) in enumerate(train_loader):\n",
    "        total_num += 3 * 8\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        y_pred = resnet(X.view(-1, 3, 225, 225))\n",
    "        loss = lossfunc(y_pred, y.view(8*3, -1)) # 16 samples in batch, 3 images in one sample\n",
    "        # find predicted labels\n",
    "        predicted = y_pred.view(8*3) > .5\n",
    "\n",
    "        # calculate the amount of correct predictions in batch\n",
    "        batch_corr += (predicted.long() == y.view(8*3)).sum()\n",
    "        # backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_corr = batch_corr.item() / (total_num)\n",
    "    epoch_end = time.time() - epoch_start\n",
    "    print(batch_corr)\n",
    "    print(f\"Epoch {epoch_i + 1} | Batch {(batch_num + 1) * 16}\\nAccuracy: {train_corr:2.2f} | Loss: {loss.item():2.4f} | Duration: {epoch_end / 60:.2f} minutes\")\n",
    "\n",
    "    train_b = batch_num\n",
    "    train_losses.append(loss)\n",
    "    train_correct.append(train_corr)\n",
    "\n",
    "    X, y = None, None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        total_num = 0\n",
    "        for batch_num, (X, y) in enumerate(valid_loader):\n",
    "            total_num += 3 * 8\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            y_val = resnet(X.view(-1, 3, 225, 225))\n",
    "            predicted = y_val.view(8*3) > .5\n",
    "\n",
    "            test_corr += (predicted.long() == y.view(8*3)).sum()\n",
    "            print((predicted.long() == y.view(8*3)).sum())\n",
    "    \n",
    "    loss = lossfunc(y_val, y.view(8*3, 1))\n",
    "\n",
    "    val_acc = test_corr.item() / (total_num)\n",
    "\n",
    "    print(f\"Validation Accuracy: {val_acc * 100:2.2f} | Validation loss: {loss.item():2.4f}\\n\")\n",
    "\n",
    "    is_best = val_acc < best_prec1\n",
    "    best_prec1 = min(val_acc, best_prec1)\n",
    "    save_checkpoint({\n",
    "        \"epoch\": epoch_i + 1,\n",
    "        \"state_dict\": resnet.state_dict(),\n",
    "        \"best_prec1\": best_prec1,\n",
    "    }, is_best)\n",
    "\n",
    "    test_b = batch_num\n",
    "    test_losses.append(loss)\n",
    "    test_correct.append(val_acc)\n",
    "\n",
    "    if earlystopping.stop_learning(val_acc):\n",
    "        break\n",
    "\n",
    "end_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nTraining Duration: {end_time / 60:.2f} minutes\")\n",
    "print(f\"GPU memory used: {torch.cuda.memory_allocated()} kb\")\n",
    "print(f\"GPU memory cached: {torch.cuda.memory_cached()} kb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(18, device='cuda:0')\n",
      "tensor(30, device='cuda:0')\n",
      "tensor(51, device='cuda:0')\n",
      "tensor(69, device='cuda:0')\n",
      "tensor(78, device='cuda:0')\n",
      "tensor(90, device='cuda:0')\n",
      "tensor(99, device='cuda:0')\n",
      "tensor(114, device='cuda:0')\n",
      "tensor(126, device='cuda:0')\n",
      "tensor(138, device='cuda:0')\n",
      "tensor(147, device='cuda:0')\n",
      "Test Loss: 2.7835\n",
      "Test accuracy: 55.681819915771484\n"
     ]
    }
   ],
   "source": [
    "# test model with no gradient updates\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    test_loss = []\n",
    "    test_corr = 0\n",
    "    labels = []\n",
    "    pred = []\n",
    "    counter = 0\n",
    "    # perform test set evaluation batch wise\n",
    "    for (X, y) in test_loader:\n",
    "        # set label to use CUDA if available\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # append original labels\n",
    "        labels.append(y.view(-1, 1))\n",
    "\n",
    "        y_pred = resnet(X.view(-1, 3, 225, 225))\n",
    "        loss = lossfunc(y_pred, y.view(8*3, -1)) # 16 samples in batch, 3 images in one sample\n",
    "\n",
    "        # get argmax of predicted values, which is our label\n",
    "        predicted = (y_val.view(8*3) > .5).long()\n",
    "        # append predicted label\n",
    "        pred.append(y_val)\n",
    "\n",
    "        # increment correct with correcly predicted labels per batch\n",
    "        test_corr += (predicted == y.view(8*3)).sum()\n",
    "        print(test_corr)\n",
    "\n",
    "        test_loss.append(loss)\n",
    "        counter += 1\n",
    "print(f\"Test Loss: {test_loss[-1].item():.4f}\")\n",
    "print(f\"Test accuracy: {test_corr * 100 / (3*8*counter)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
